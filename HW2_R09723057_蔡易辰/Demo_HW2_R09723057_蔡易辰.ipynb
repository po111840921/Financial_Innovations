{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 題目\n",
    "### Use LSTM & CNN model to classify MNIST dataset with at least 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *此處使用檔案為去掉學號與姓名之檔案名稱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *以keras套件為主執行機器學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、程式碼\n",
    "* 所有檔案: mnist_lstm.py、mnist_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. mnist_lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lstm:\n",
    "又稱長短期記憶（Long Short-Term Memory）是一種時間循環神經網路（RNN），LSTM適合於處理和預測時間序列中間隔和延遲非常長的重要事件。\n",
    "為了最小化訓練誤差，梯度下降法（Gradient descent）如：應用時序性倒傳遞演算法，可用來依據錯誤修改每次的權重。梯度下降法在循環神經網路（RNN）中主要的問題初次在1991年發現，就是誤差梯度隨著事件間的時間長度成指數般的消失。當設置了LSTM 區塊時，誤差也隨著倒回計算，從output影響回input階段的每一個gate，直到這個數值被過濾掉。因此正常的倒循環類神經是一個有效訓練LSTM區塊記住長時間數值的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def trainning(model, x_train, y_train, x_test, y_test, \n",
    "              learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size, epochs=training_iters,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_confusion_result(x_train, x_test, y_train, y_test, model):\n",
    "    # get train & test predictions\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    # get train & test true labels\n",
    "    train_label = y_train\n",
    "    test_label =  y_test\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(10))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(10))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 28\n",
    "    n_step = 28\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. mnist_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN:\n",
    "卷積神經網路（Convolutional Neural Network, CNN）是一種前饋神經網路，它的人工神經元可以回應一部分覆蓋範圍內的周圍單元，對於大型圖像處理有出色表現。\n",
    "\n",
    "卷積神經網路由一個或多個卷積層和頂端的全連通層（對應經典的神經網路）組成，同時也包括關聯權重和池化層（pooling layer）。這一結構使得卷積神經網路能夠利用輸入資料的二維結構。與其他深度學習結構相比，卷積神經網路在圖像和語音辨識方面能夠給出更好的結果。這一模型也可以使用反向傳播演算法進行訓練。相比較其他深度、前饋神經網路，卷積神經網路需要考量的參數更少，使之成為一種頗具吸引力的深度學習結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def cnn_preprocess(x_train, x_test, y_train, y_test):\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def trainning(model, x_train, y_train, x_test, y_test, \n",
    "              learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size, epochs=training_iters,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_confusion_result(x_train, x_test, y_train, y_test, model):\n",
    "    # get train & test predictions\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    # get train & test true labels\n",
    "    train_label = y_train\n",
    "    test_label =  y_test\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(10))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(10))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "\n",
    "\n",
    "def mnist_cnn_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 64\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = cnn_preprocess(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    model = cnn_model()\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('CNN test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、執行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. LSTM\n",
    "* Accuracy（準確性）: 0.9560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 294,410\n",
      "Trainable params: 294,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.4525 - accuracy: 0.8487 - val_loss: 0.1395 - val_accuracy: 0.9560\n",
      "LSTM test accuracy: 0.9559999704360962\n",
      "[[5710    2   31   13    8   47   63    1   29   19]\n",
      " [   2 6629   25   36    8    6    7   22    4    3]\n",
      " [   9   19 5744   49   15   14   24   60   21    3]\n",
      " [   3   20   87 5857    0   54    5   52   43   10]\n",
      " [   3    7   12    0 5603   15   50   39    8  105]\n",
      " [   5   10   13   35   11 5219   88    2   32    6]\n",
      " [  12    5    7    1   27   27 5825    0   14    0]\n",
      " [   4   11   59   28    7   19    0 6064    5   68]\n",
      " [  16   48   28  214   19  189   43    8 5224   62]\n",
      " [  14    7    8   44  111   75    6  110   54 5520]] \n",
      "\n",
      " [[ 955    0    1    4    2    6    6    1    1    4]\n",
      " [   1 1121    4    2    0    1    4    1    1    0]\n",
      " [   0    0 1006    9    1    1    4    9    1    1]\n",
      " [   0    0   16  972    0    6    0    9    7    0]\n",
      " [   0    1    3    0  934    3   14    3    1   23]\n",
      " [   2    0    2    8    0  860   12    1    7    0]\n",
      " [   7    2    1    0    9    6  930    0    3    0]\n",
      " [   1    6   18    8    0    2    0  984    1    8]\n",
      " [   9    3    2   52    6   31    7    5  853    6]\n",
      " [   4    2    0    4   16    8    1   12   17  945]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CNN\n",
    "* Accuracy（準確性）: 0.9889\n",
    "* 此資料中ＣＮＮ表現比較好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 48)        38448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 84)                21588     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.1429 - accuracy: 0.9560 - val_loss: 0.0362 - val_accuracy: 0.9889\n",
      "CNN test accuracy: 0.9889000058174133\n",
      "[[5876    0   13    1    0    5   19    0    5    4]\n",
      " [   1 6652   36    0    3    2   22   17    9    0]\n",
      " [   3    5 5924    8    1    1    1   11    2    2]\n",
      " [   1    0   34 6015    0   37    1   24    8   11]\n",
      " [   2    6   12    0 5795    0    7    5    2   13]\n",
      " [   3    1    7   12    0 5347   28    1   14    8]\n",
      " [   4    0    4    1    5    6 5892    0    6    0]\n",
      " [   6    7   34    3    5    1    0 6190    3   16]\n",
      " [   4   10   39    4    7   21   15    3 5733   15]\n",
      " [  18    5   11    7   33   15    1   34   17 5808]] \n",
      "\n",
      " [[ 972    0    0    0    0    1    3    1    3    0]\n",
      " [   0 1125    2    0    0    0    6    1    1    0]\n",
      " [   1    0 1029    0    0    0    0    1    1    0]\n",
      " [   1    0    4  997    0    4    0    3    1    0]\n",
      " [   0    0    3    0  975    0    1    0    0    3]\n",
      " [   2    0    1    6    0  879    2    0    0    2]\n",
      " [   1    1    0    0    2    1  950    0    3    0]\n",
      " [   0    1    6    0    0    0    0 1019    1    1]\n",
      " [   3    0    3    2    0    1    0    1  964    0]\n",
      " [   4    4    0    3    7    5    0    4    3  979]]\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/pecu/FinTech_CommonWealth_Magazine/tree/master/Financial_Innovation/FiancailVision/HW2_ID_%E5%A7%93%E5%90%8D\n",
    "\n",
    "- \n",
    "https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\n",
    "\n",
    "- \n",
    "https://zh.wikipedia.org/zh-tw/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6\n",
    "\n",
    "- \n",
    "[LSTM_深度學習_股價預測](https://medium.com/data-scientists-playground/lstm-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E8%82%A1%E5%83%B9%E9%A0%90%E6%B8%AC-cd72af64413a)\n",
    "\n",
    "- \n",
    "[卷積神經網絡介紹(Convolutional Neural Network)](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC5-1%E8%AC%9B-%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1%E4%BB%8B%E7%B4%B9-convolutional-neural-network-4f8249d65d4f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
