HW2: use LSTM and CNN model to classify MNIST dataset with at least 90%

*此處使用檔案為去掉學號與姓名之檔案名稱並以keras套件為主執行機器學習

比較資料集後發現CNN表現比較好



Lstm:
又稱長短期記憶（Long Short-Term Memory）是一種時間循環神經網路（RNN），LSTM適合於處理和預測時間序列中間隔和延遲非常長的重要事件。
為了最小化訓練誤差，梯度下降法（Gradient descent）如：應用時序性倒傳遞演算法，可用來依據錯誤修改每次的權重。梯度下降法在循環神經網路（RNN）中主要的問題初次在1991年發現，
就是誤差梯度隨著事件間的時間長度成指數般的消失。當設置了LSTM 區塊時，誤差也隨著倒回計算，從output影響回input階段的每一個gate，直到這個數值被過濾掉。
因此正常的倒循環類神經是一個有效訓練LSTM區塊記住長時間數值的方法。

CNN:
卷積神經網路（Convolutional Neural Network, CNN）是一種前饋神經網路，它的人工神經元可以回應一部分覆蓋範圍內的周圍單元，對於大型圖像處理有出色表現。
卷積神經網路由一個或多個卷積層和頂端的全連通層（對應經典的神經網路）組成，同時也包括關聯權重和池化層（pooling layer）。
這一結構使得卷積神經網路能夠利用輸入資料的二維結構。與其他深度學習結構相比，卷積神經網路在圖像和語音辨識方面能夠給出更好的結果。
這一模型也可以使用反向傳播演算法進行訓練。相比較其他深度、前饋神經網路，卷積神經網路需要考量的參數更少，使之成為一種頗具吸引力的深度學習結構
