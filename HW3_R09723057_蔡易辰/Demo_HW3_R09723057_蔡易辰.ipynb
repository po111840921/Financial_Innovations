{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 題目\n",
    "### Use LSTM & CNN model to classify customized candlestick pattern (at least 3 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 所有檔案: candlestick_lstm_R09723057_蔡易辰.py、candlestick_cnn_R09723057_蔡易辰.py\n",
    "* 此處使用本機連結，使用請更改連結"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use LSTM model to classify customized candlestick pattern\n",
    "* candlestick_lstm_R09723057_蔡易辰.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_lstm(model, x_train, y_train, x_test, y_test, \n",
    "        learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam,\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "        batch_size=batch_size, epochs=training_iters,\n",
    "        verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_result(data, x_train, x_test, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def candlestick_lstm_main(iters):\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = iters\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 40\n",
    "    n_step = 10\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "    \n",
    "    #此處連結改成本機連結\n",
    "    data = load_pkl('C:\\\\Users\\\\TsaiYiChen\\\\Desktop\\\\ntu_financial_innovation\\\\label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl')\n",
    "    x_train, y_train, x_test, y_test = data['train_gaf'], data['train_label'][:, 0], data['test_gaf'], data['test_label'][:, 0]\n",
    "    x_train, x_test, y_train, y_test = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    train_lstm(model, x_train, y_train, x_test, y_test, learning_rate, \n",
    "               training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_result(data, x_train, x_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM - 10 iterations\n",
    "* 發現第九次效果最佳\n",
    "* The ninth iteration has the best result with accuracy equals to 0.7906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 12s 804us/step - loss: 2.1313 - accuracy: 0.2005 - val_loss: 1.6804 - val_accuracy: 0.2278\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 12s 773us/step - loss: 1.5394 - accuracy: 0.3229 - val_loss: 1.5197 - val_accuracy: 0.3202\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 11s 702us/step - loss: 1.3491 - accuracy: 0.3976 - val_loss: 1.4304 - val_accuracy: 0.3450\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 11s 701us/step - loss: 1.2884 - accuracy: 0.4223 - val_loss: 1.2825 - val_accuracy: 0.4218\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 11s 709us/step - loss: 1.2613 - accuracy: 0.4393 - val_loss: 1.2696 - val_accuracy: 0.4388\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 11s 717us/step - loss: 1.1861 - accuracy: 0.4875 - val_loss: 1.1269 - val_accuracy: 0.4938\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 11s 729us/step - loss: 1.0458 - accuracy: 0.5713 - val_loss: 0.9139 - val_accuracy: 0.6238\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 11s 711us/step - loss: 0.7913 - accuracy: 0.6851 - val_loss: 0.7103 - val_accuracy: 0.7234\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 10s 699us/step - loss: 0.7055 - accuracy: 0.7251 - val_loss: 0.5740 - val_accuracy: 0.7906\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 10s 696us/step - loss: 0.6325 - accuracy: 0.7557 - val_loss: 0.6130 - val_accuracy: 0.7646\n",
      "LSTM test accuracy: 0.7645999789237976\n",
      "[[1517  301  280  168   56  264  167  199   48]\n",
      " [  27 1347    0  126    0    0    0    0    0]\n",
      " [ 177    0 1320    0    3    0    0    0    0]\n",
      " [  11   45    0 1317    0    0    0  127    0]\n",
      " [  43    0  297    0 1049    0    5    0  106]\n",
      " [  50    6    0    4    0 1312    0  128    0]\n",
      " [ 431    2    0    0    1    0 1046    0   20]\n",
      " [   8    1    0  272    0    5    0 1214    0]\n",
      " [  72    0   18    0  189    0  151    0 1070]] \n",
      "\n",
      " [[528  83 103  59  19  89  37  62  20]\n",
      " [ 13 428   0  59   0   0   0   0   0]\n",
      " [ 58   0 442   0   0   0   0   0   0]\n",
      " [  8   4   0 452   0   0   0  36   0]\n",
      " [ 13   0 110   0 339   0   2   0  36]\n",
      " [ 17   0   0   1   0 451   0  31   0]\n",
      " [119   0   1   0   0   0 377   0   3]\n",
      " [  3   0   0  60   0   3   0 434   0]\n",
      " [ 34   0   1   0  42   0  51   0 372]]\n"
     ]
    }
   ],
   "source": [
    "candlestick_lstm_main(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM - 50 iterations\n",
    "* The 31th iteration has the best result with accuracy equals to 0.8752\n",
    "* Generally, 50 iterations does better than 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "15000/15000 [==============================] - 12s 810us/step - loss: 2.1387 - accuracy: 0.2014 - val_loss: 1.6452 - val_accuracy: 0.2510\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 11s 721us/step - loss: 1.5118 - accuracy: 0.3329 - val_loss: 1.3198 - val_accuracy: 0.4054\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 12s 771us/step - loss: 1.3441 - accuracy: 0.4089 - val_loss: 1.2618 - val_accuracy: 0.4620\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 11s 747us/step - loss: 1.1906 - accuracy: 0.5057 - val_loss: 1.0801 - val_accuracy: 0.5662\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 11s 748us/step - loss: 0.9847 - accuracy: 0.6135 - val_loss: 0.9866 - val_accuracy: 0.6110\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 11s 722us/step - loss: 0.8349 - accuracy: 0.6699 - val_loss: 0.7737 - val_accuracy: 0.7032\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 11s 722us/step - loss: 0.6876 - accuracy: 0.7321 - val_loss: 0.7187 - val_accuracy: 0.7100\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 11s 727us/step - loss: 0.6403 - accuracy: 0.7502 - val_loss: 0.9343 - val_accuracy: 0.6470\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 11s 715us/step - loss: 0.6178 - accuracy: 0.7637 - val_loss: 0.5659 - val_accuracy: 0.7864\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 11s 718us/step - loss: 0.5782 - accuracy: 0.7773 - val_loss: 0.8879 - val_accuracy: 0.6704\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 11s 703us/step - loss: 0.5754 - accuracy: 0.7779 - val_loss: 0.5528 - val_accuracy: 0.7986\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 11s 710us/step - loss: 0.5574 - accuracy: 0.7891 - val_loss: 0.5245 - val_accuracy: 0.8020\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 11s 720us/step - loss: 0.5483 - accuracy: 0.7901 - val_loss: 0.6191 - val_accuracy: 0.7548\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 10s 697us/step - loss: 0.5511 - accuracy: 0.7877 - val_loss: 0.4482 - val_accuracy: 0.8342\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 11s 717us/step - loss: 0.5249 - accuracy: 0.8035 - val_loss: 0.4269 - val_accuracy: 0.8488\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 11s 718us/step - loss: 0.5386 - accuracy: 0.7947 - val_loss: 0.5880 - val_accuracy: 0.7854\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 11s 728us/step - loss: 0.5156 - accuracy: 0.8063 - val_loss: 0.4870 - val_accuracy: 0.8134\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 11s 709us/step - loss: 0.5139 - accuracy: 0.8059 - val_loss: 0.4037 - val_accuracy: 0.8540\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 11s 720us/step - loss: 0.4973 - accuracy: 0.8143 - val_loss: 0.4795 - val_accuracy: 0.8168\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 11s 720us/step - loss: 0.4727 - accuracy: 0.8216 - val_loss: 0.4335 - val_accuracy: 0.8404\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 11s 706us/step - loss: 0.4997 - accuracy: 0.8085 - val_loss: 0.4289 - val_accuracy: 0.8456\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 11s 714us/step - loss: 0.4783 - accuracy: 0.8206 - val_loss: 0.9006 - val_accuracy: 0.6762\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 11s 710us/step - loss: 0.5153 - accuracy: 0.8077 - val_loss: 0.4178 - val_accuracy: 0.8444\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 11s 707us/step - loss: 0.4609 - accuracy: 0.8269 - val_loss: 0.4528 - val_accuracy: 0.8288\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 11s 727us/step - loss: 0.4580 - accuracy: 0.8277 - val_loss: 0.3741 - val_accuracy: 0.8690\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 11s 706us/step - loss: 0.4581 - accuracy: 0.8275 - val_loss: 0.3672 - val_accuracy: 0.8728\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 11s 709us/step - loss: 0.4549 - accuracy: 0.8293 - val_loss: 0.5267 - val_accuracy: 0.8184\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 11s 730us/step - loss: 0.4584 - accuracy: 0.8269 - val_loss: 0.3860 - val_accuracy: 0.8582\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 11s 721us/step - loss: 0.4529 - accuracy: 0.8262 - val_loss: 0.4012 - val_accuracy: 0.8510\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 11s 707us/step - loss: 0.4366 - accuracy: 0.8385 - val_loss: 0.4355 - val_accuracy: 0.8340\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 11s 726us/step - loss: 0.4355 - accuracy: 0.8352 - val_loss: 0.3635 - val_accuracy: 0.8752\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 11s 720us/step - loss: 0.4417 - accuracy: 0.8342 - val_loss: 0.4003 - val_accuracy: 0.8514\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 11s 734us/step - loss: 0.4464 - accuracy: 0.8312 - val_loss: 0.3917 - val_accuracy: 0.8570\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 11s 705us/step - loss: 0.4335 - accuracy: 0.8350 - val_loss: 0.5128 - val_accuracy: 0.7996\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 11s 719us/step - loss: 0.4472 - accuracy: 0.8294 - val_loss: 0.3697 - val_accuracy: 0.8696\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 11s 718us/step - loss: 0.4322 - accuracy: 0.8375 - val_loss: 0.3658 - val_accuracy: 0.8706\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 11s 708us/step - loss: 0.4439 - accuracy: 0.8317 - val_loss: 0.4080 - val_accuracy: 0.8546\n",
      "Epoch 38/50\n",
      "15000/15000 [==============================] - 11s 737us/step - loss: 0.4346 - accuracy: 0.8339 - val_loss: 0.3720 - val_accuracy: 0.8682\n",
      "Epoch 39/50\n",
      "15000/15000 [==============================] - 12s 776us/step - loss: 0.4412 - accuracy: 0.8337 - val_loss: 0.3672 - val_accuracy: 0.8692\n",
      "Epoch 40/50\n",
      "15000/15000 [==============================] - 11s 705us/step - loss: 0.4558 - accuracy: 0.8256 - val_loss: 0.3849 - val_accuracy: 0.8660\n",
      "Epoch 41/50\n",
      "15000/15000 [==============================] - 11s 708us/step - loss: 0.4237 - accuracy: 0.8405 - val_loss: 0.3721 - val_accuracy: 0.8646\n",
      "Epoch 42/50\n",
      "15000/15000 [==============================] - 10s 690us/step - loss: 0.4277 - accuracy: 0.8373 - val_loss: 0.4178 - val_accuracy: 0.8460\n",
      "Epoch 43/50\n",
      "15000/15000 [==============================] - 10s 694us/step - loss: 0.4430 - accuracy: 0.8312 - val_loss: 0.4251 - val_accuracy: 0.8484\n",
      "Epoch 44/50\n",
      "15000/15000 [==============================] - 11s 712us/step - loss: 0.4249 - accuracy: 0.8385 - val_loss: 0.3970 - val_accuracy: 0.8534\n",
      "Epoch 45/50\n",
      "15000/15000 [==============================] - 11s 719us/step - loss: 0.4293 - accuracy: 0.8370 - val_loss: 0.3606 - val_accuracy: 0.8748\n",
      "Epoch 46/50\n",
      "15000/15000 [==============================] - 11s 707us/step - loss: 0.4222 - accuracy: 0.8422 - val_loss: 0.4097 - val_accuracy: 0.8488\n",
      "Epoch 47/50\n",
      "15000/15000 [==============================] - 11s 703us/step - loss: 0.4312 - accuracy: 0.8377 - val_loss: 0.3969 - val_accuracy: 0.8558\n",
      "Epoch 48/50\n",
      "15000/15000 [==============================] - 11s 730us/step - loss: 0.4125 - accuracy: 0.8461 - val_loss: 0.4981 - val_accuracy: 0.8144\n",
      "Epoch 49/50\n",
      "15000/15000 [==============================] - 11s 708us/step - loss: 0.4353 - accuracy: 0.8362 - val_loss: 0.3581 - val_accuracy: 0.8738\n",
      "Epoch 50/50\n",
      "15000/15000 [==============================] - 11s 752us/step - loss: 0.4117 - accuracy: 0.8450 - val_loss: 0.3757 - val_accuracy: 0.8666\n",
      "LSTM test accuracy: 0.866599977016449\n",
      "[[2027  159   98  138  106  198   85  133   56]\n",
      " [  34 1458    0    8    0    0    0    0    0]\n",
      " [ 110    0 1384    0    6    0    0    0    0]\n",
      " [  16   21    0 1305    0    0    0  158    0]\n",
      " [  65    0   36    0 1365    0    0    0   34]\n",
      " [  22    2    0    1    0 1451    0   24    0]\n",
      " [ 121    4    0    0    3    0 1343    0   29]\n",
      " [  12    0    0  168    0   19    0 1301    0]\n",
      " [  55    0    2    0  320    0   28    0 1095]] \n",
      "\n",
      " [[687  45  37  41  38  69  21  42  20]\n",
      " [ 11 485   0   4   0   0   0   0   0]\n",
      " [ 31   0 469   0   0   0   0   0   0]\n",
      " [ 12   9   0 445   0   0   0  34   0]\n",
      " [ 28   0  27   0 438   0   0   0   7]\n",
      " [  7   0   0   0   0 493   0   0   0]\n",
      " [ 34   0   1   0   0   0 460   0   5]\n",
      " [  7   0   0  18   0   7   0 468   0]\n",
      " [ 27   0   0   0  78   0   7   0 388]]\n"
     ]
    }
   ],
   "source": [
    "candlestick_lstm_main(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use CNN model to classify customized candlestick pattern\n",
    "* candlestick_cnn_R09723057_蔡易辰.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPool2D\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def get_cnn_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(10, 10, 4)))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(params, data):\n",
    "    model = get_cnn_model(params)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    hist = model.fit(x=data['train_gaf'], y=data['train_label_arr'],\n",
    "                     batch_size=params['batch_size'], epochs=params['epochs'], verbose=2)\n",
    "    return (model, hist)\n",
    "\n",
    "def print_result(data, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(data['train_gaf'])\n",
    "    test_pred = model.predict_classes(data['test_gaf'])\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss: 1.5741 - accuracy: 0.4170\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.7894 - accuracy: 0.7139\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.5994 - accuracy: 0.7837\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.5308 - accuracy: 0.8045\n",
      "Epoch 5/10\n",
      " - 6s - loss: 0.4904 - accuracy: 0.8217\n",
      "Epoch 6/10\n",
      " - 6s - loss: 0.4649 - accuracy: 0.8292\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.4430 - accuracy: 0.8419\n",
      "Epoch 8/10\n",
      " - 6s - loss: 0.4317 - accuracy: 0.8443\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.4134 - accuracy: 0.8524\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.4036 - accuracy: 0.8503\n",
      "CNN test accuracy: 0.8086000084877014\n",
      "[[2438   61   75   43   73  116  115   11   68]\n",
      " [  80 1417    0    2    0    0    1    0    0]\n",
      " [ 128    0 1359    0   13    0    0    0    0]\n",
      " [ 326   25    0 1088    0    2    0   59    0]\n",
      " [ 100    0   22    0 1253    0    5    0  120]\n",
      " [  93    2    0    0    0 1400    2    3    0]\n",
      " [  93    1    1    0    1    0 1376    0   28]\n",
      " [ 727    0    0   88    0   83    0  602    0]\n",
      " [  70    0    2    0  117    0   48    0 1263]] \n",
      "\n",
      " [[817  20  29  14  24  42  28   4  22]\n",
      " [ 32 467   0   1   0   0   0   0   0]\n",
      " [ 33   0 466   0   1   0   0   0   0]\n",
      " [114  10   0 356   0   1   0  19   0]\n",
      " [ 52   0   9   0 394   0   2   0  43]\n",
      " [ 38   0   0   0   0 462   0   0   0]\n",
      " [ 32   0   1   0   0   0 463   0   4]\n",
      " [282   1   0   4   0  24   0 189   0]\n",
      " [ 30   0   0   0  22   0  19   0 429]]\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {}\n",
    "#改成本機連結\n",
    "PARAMS['pkl_name'] = 'C:\\\\Users\\\\TsaiYiChen\\\\Desktop\\\\ntu_financial_innovation\\\\label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl'\n",
    "PARAMS['classes'] = 9\n",
    "PARAMS['lr'] = 0.01\n",
    "PARAMS['epochs'] = 10\n",
    "PARAMS['batch_size'] = 64\n",
    "PARAMS['optimizer'] = optimizers.SGD(lr=PARAMS['lr'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# load data & keras model\n",
    "data = load_pkl(PARAMS['pkl_name'])\n",
    "# train cnn model\n",
    "model, hist = train_model(PARAMS, data)\n",
    "# train & test result\n",
    "scores = model.evaluate(data['test_gaf'], data['test_label_arr'], verbose=0)\n",
    "print('CNN test accuracy:', scores[1])\n",
    "print_result(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Under 10 iterations, CNN does better than LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/pecu/FinTech_CommonWealth_Magazine/tree/master/Financial_Innovation/FiancailVision/HW2_ID_%E5%A7%93%E5%90%8D\n",
    "- \n",
    "[Keras:基于Python的深度学习库](https://keras-cn.readthedocs.io/en/latest/)\n",
    "- \n",
    "[Keras資料庫](https://keras.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
